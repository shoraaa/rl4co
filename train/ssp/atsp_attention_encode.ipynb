{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beee891e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, RichModelSummary\n",
    "\n",
    "from rl4co.envs import SSPkoptEnv, ATSPkoptEnv, TSPkoptEnv\n",
    "from rl4co.models import NeuOptPolicy, NeuOpt\n",
    "from rl4co.models.nn.env_embeddings.edge import ATSPEdgeEmbedding\n",
    "from rl4co.utils.trainer import RL4COTrainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0828749e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shora/Research/rl4co/.venv/lib/python3.13/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'critic' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['critic'])`.\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CustomizeATSPInitEmbedding(nn.Module):\n",
    "    def __init__(self, embed_dim, num_loc, linear_bias=True):\n",
    "        super(CustomizeATSPInitEmbedding, self).__init__()\n",
    "        node_dim = num_loc\n",
    "        self.init_embed = nn.Sequential(\n",
    "            # nn.LayerNorm(node_dim),\n",
    "            nn.Linear(node_dim, embed_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=4)\n",
    "\n",
    "\n",
    "    def forward(self, td):\n",
    "        cost_embed = self.init_embed(td[\"cost_matrix\"])  # [B, N, embed_dim]\n",
    "        out = self.encoder(cost_embed)  # Inject global context\n",
    "        return out\n",
    "\n",
    "num_loc = 10  # Number of strings\n",
    "fixed_len = 15\n",
    "embed_dim = 128  # Dimension of the embedding space\n",
    "\n",
    "env = SSPkoptEnv(generator_params=dict(num_loc=num_loc, fixed_len=fixed_len, init_sol_type=\"random\"), k_max=4)\n",
    "model = NeuOpt(\n",
    "        env,\n",
    "        batch_size=128,\n",
    "        train_data_size=1000,\n",
    "        val_data_size=100,\n",
    "        test_data_size=100,\n",
    "        n_step=5,\n",
    "        T_train=200,\n",
    "        T_test=1000,\n",
    "        CL_best=True,\n",
    "        policy_kwargs=dict(\n",
    "            embed_dim=embed_dim,\n",
    "            init_embedding=CustomizeATSPInitEmbedding(num_loc=num_loc,embed_dim=embed_dim),\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90fe6f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(  dirpath=\"checkpoints_atsp\", # save to checkpoints/\n",
    "                                        filename=\"atsp_attention_encode{epoch:03d}\",  # save as epoch_XXX.ckpt\n",
    "                                        save_top_k=1, # save only the best model\n",
    "                                        save_last=True, # save the last model\n",
    "                                        monitor=\"val/cost_bsf\", # monitor validation reward\n",
    "                                        mode=\"min\") # maximize validation reward\n",
    "\n",
    "\n",
    "rich_model_summary = RichModelSummary(max_depth=3)\n",
    "\n",
    "callbacks = [checkpoint_callback, rich_model_summary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be470385",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.loggers import WandbLogger\n",
    "logger = WandbLogger(project=\"rl4co\", name=\"atsp_attention_encode\", log_model=True, save_dir=\"wandb_logs\")\n",
    "\n",
    "#  logger = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24d88038",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = RL4COTrainer(\n",
    "    max_epochs=20,\n",
    "    gradient_clip_val=0.05,\n",
    "    devices=1,\n",
    "    accelerator=\"gpu\",\n",
    "    logger=logger,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9da24d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshoraaa\u001b[0m (\u001b[33mshoraaa-vnu\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.6s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>wandb_logs/wandb/run-20250703_081403-rnaeiew1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/shoraaa-vnu/rl4co/runs/rnaeiew1' target=\"_blank\">atsp_attention_encode</a></strong> to <a href='https://wandb.ai/shoraaa-vnu/rl4co' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/shoraaa-vnu/rl4co' target=\"_blank\">https://wandb.ai/shoraaa-vnu/rl4co</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/shoraaa-vnu/rl4co/runs/rnaeiew1' target=\"_blank\">https://wandb.ai/shoraaa-vnu/rl4co/runs/rnaeiew1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/shora/Research/rl4co/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd1d21859cf24bd5b2affd8d95102a53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/rl4co/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/call.py:48\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     47\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/rl4co/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/trainer.py:817\u001b[39m, in \u001b[36mTrainer._test_impl\u001b[39m\u001b[34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[39m\n\u001b[32m    814\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    815\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn, ckpt_path, model_provided=model_provided, model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    816\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m817\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    818\u001b[39m \u001b[38;5;66;03m# remove the tensors from the test results\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/rl4co/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/trainer.py:1012\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m   1009\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1010\u001b[39m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[32m   1011\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1012\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1015\u001b[39m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[32m   1016\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/rl4co/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/trainer.py:1049\u001b[39m, in \u001b[36mTrainer._run_stage\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1048\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.evaluating:\n\u001b[32m-> \u001b[39m\u001b[32m1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_evaluation_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1050\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.predicting:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/rl4co/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/utilities.py:179\u001b[39m, in \u001b[36m_no_grad_context.<locals>._decorator\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/rl4co/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/evaluation_loop.py:145\u001b[39m, in \u001b[36m_EvaluationLoop.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    144\u001b[39m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_evaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    147\u001b[39m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/rl4co/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/evaluation_loop.py:437\u001b[39m, in \u001b[36m_EvaluationLoop._evaluation_step\u001b[39m\u001b[34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[39m\n\u001b[32m    432\u001b[39m step_args = (\n\u001b[32m    433\u001b[39m     \u001b[38;5;28mself\u001b[39m._build_step_args_from_hook_kwargs(hook_kwargs, hook_name)\n\u001b[32m    434\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_dataloader_iter\n\u001b[32m    435\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m (dataloader_iter,)\n\u001b[32m    436\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m437\u001b[39m output = \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mstep_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[38;5;28mself\u001b[39m.batch_progress.increment_processed()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/rl4co/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/call.py:328\u001b[39m, in \u001b[36m_call_strategy_hook\u001b[39m\u001b[34m(trainer, hook_name, *args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trainer.profiler.profile(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer.strategy.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     output = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/rl4co/.venv/lib/python3.13/site-packages/lightning/pytorch/strategies/strategy.py:425\u001b[39m, in \u001b[36mStrategy.test_step\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    424\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_redirection(\u001b[38;5;28mself\u001b[39m.model, \u001b[38;5;28mself\u001b[39m.lightning_module, \u001b[33m\"\u001b[39m\u001b[33mtest_step\u001b[39m\u001b[33m\"\u001b[39m, *args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m425\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlightning_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtest_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/rl4co/rl4co/models/rl/common/base.py:266\u001b[39m, in \u001b[36mRL4COLitModule.test_step\u001b[39m\u001b[34m(self, batch, batch_idx, dataloader_idx)\u001b[39m\n\u001b[32m    265\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtest_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch: Any, batch_idx: \u001b[38;5;28mint\u001b[39m, dataloader_idx: \u001b[38;5;28mint\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshared_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphase\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtest\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataloader_idx\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/rl4co/rl4co/models/rl/ppo/n_step_ppo.py:124\u001b[39m, in \u001b[36mn_step_PPO.shared_step\u001b[39m\u001b[34m(self, batch, batch_idx, phase, dataloader_idx)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.ppo_cfg[\u001b[33m\"\u001b[39m\u001b[33mT_test\u001b[39m\u001b[33m\"\u001b[39m]):\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m     out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphase\u001b[49m\u001b[43m=\u001b[49m\u001b[43mphase\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    125\u001b[39m     \u001b[38;5;28mself\u001b[39m.env.step(td)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/rl4co/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/rl4co/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/rl4co/rl4co/models/zoo/neuopt/policy.py:207\u001b[39m, in \u001b[36mNeuOptPolicy.forward\u001b[39m\u001b[34m(self, td, env, phase, return_actions, return_embeds, only_return_embed, actions, **decoding_kwargs)\u001b[39m\n\u001b[32m    205\u001b[39m     mask = mask.scatter(\u001b[32m1\u001b[39m, td[\u001b[33m\"\u001b[39m\u001b[33maction\u001b[39m\u001b[33m\"\u001b[39m][:, :\u001b[32m1\u001b[39m], \u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m logprob, action_sampled = \u001b[43mdecode_strategy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m    \u001b[49m\u001b[43m~\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m    \u001b[49m\u001b[43maction\u001b[49m\u001b[43m=\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    212\u001b[39m action_sampled = action_sampled.unsqueeze(-\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/rl4co/rl4co/utils/decoding.py:374\u001b[39m, in \u001b[36mDecodingStrategy.step\u001b[39m\u001b[34m(self, logits, mask, td, action, **kwargs)\u001b[39m\n\u001b[32m    365\u001b[39m logprobs = process_logits(\n\u001b[32m    366\u001b[39m     logits,\n\u001b[32m    367\u001b[39m     mask,\n\u001b[32m   (...)\u001b[39m\u001b[32m    372\u001b[39m     mask_logits=\u001b[38;5;28mself\u001b[39m.mask_logits,\n\u001b[32m    373\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m374\u001b[39m logprobs, selected_action, td = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m=\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[38;5;66;03m# directly return for improvement methods, since the action for improvement methods is finalized in its own policy\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/rl4co/rl4co/utils/decoding.py:448\u001b[39m, in \u001b[36mSampling._step\u001b[39m\u001b[34m(self, logprobs, mask, td, **kwargs)\u001b[39m\n\u001b[32m    447\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Sample an action with a multinomial distribution given by the log probabilities.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m448\u001b[39m selected = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msampling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    449\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m logprobs, selected, td\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/rl4co/rl4co/utils/decoding.py:407\u001b[39m, in \u001b[36mDecodingStrategy.sampling\u001b[39m\u001b[34m(logprobs, mask)\u001b[39m\n\u001b[32m    406\u001b[39m probs = logprobs.exp()\n\u001b[32m--> \u001b[39m\u001b[32m407\u001b[39m selected = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmultinomial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m.squeeze(\u001b[32m1\u001b[39m)\n\u001b[32m    409\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/rl4co/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/trainer.py:775\u001b[39m, in \u001b[36mTrainer.test\u001b[39m\u001b[34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[39m\n\u001b[32m    773\u001b[39m \u001b[38;5;28mself\u001b[39m.state.status = TrainerStatus.RUNNING\n\u001b[32m    774\u001b[39m \u001b[38;5;28mself\u001b[39m.testing = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m775\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    776\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_test_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\n\u001b[32m    777\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/rl4co/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/call.py:65\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[32m     64\u001b[39m         launcher.kill(_get_sigkill_signal())\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[43mexit\u001b[49m(\u001b[32m1\u001b[39m)\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[32m     68\u001b[39m     _interrupt(trainer, exception)\n",
      "\u001b[31mNameError\u001b[39m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "trainer.test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb010052",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding gradient_clip_val to None for 'automatic_optimization=False' models\n",
      "/home/shora/Research/rl4co/.venv/lib/python3.13/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:658: Checkpoint directory /home/shora/Research/rl4co/train/checkpoints_tsp exists and is not empty.\n",
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/shora/Research/rl4co/.venv/lib/python3.13/site-packages/lightning/pytorch/core/optimizer.py:317: The lr scheduler dict contains the key(s) ['monitor'], but the keys will be ignored. You need to call `lr_scheduler.step()` manually in manual optimization.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">    </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name                            </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                       </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0  </span>│ env                             │ ATSPkoptEnv                │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1  </span>│ policy                          │ NeuOptPolicy               │  1.3 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2  </span>│ policy.encoder                  │ N2SEncoder                 │  940 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3  </span>│ policy.encoder.init_embedding   │ CustomizeATSPInitEmbedding │  612 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4  </span>│ policy.encoder.pos_embedding    │ CyclicPositionalEmbedding  │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5  </span>│ policy.encoder.pos_net          │ MultiHeadCompat            │ 32.8 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6  </span>│ policy.encoder.net              │ AdaptiveSequential         │  295 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7  </span>│ policy.decoder                  │ RDSDecoder                 │  329 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8  </span>│ policy.decoder.linear_K1        │ Linear                     │ 16.4 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9  </span>│ policy.decoder.linear_K2        │ Linear                     │ 16.4 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 10 </span>│ policy.decoder.linear_K3        │ Linear                     │ 16.4 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 11 </span>│ policy.decoder.linear_K4        │ Linear                     │ 16.4 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 12 </span>│ policy.decoder.linear_Q1        │ Linear                     │ 16.4 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 13 </span>│ policy.decoder.linear_Q2        │ Linear                     │ 16.4 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 14 </span>│ policy.decoder.linear_Q3        │ Linear                     │ 16.4 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 15 </span>│ policy.decoder.linear_Q4        │ Linear                     │ 16.4 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 16 </span>│ policy.decoder.rnn1             │ GRUCell                    │ 99.1 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 17 </span>│ policy.decoder.rnn2             │ GRUCell                    │ 99.1 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 18 </span>│ policy.init_hidden_W            │ Linear                     │ 16.5 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 19 </span>│ critic                          │ CriticNetwork              │  140 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 20 </span>│ critic.encoder                  │ MultiHeadAttentionLayer    │ 98.6 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 21 </span>│ critic.encoder.0                │ SkipConnection             │ 65.5 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 22 </span>│ critic.encoder.1                │ Normalization              │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 23 </span>│ critic.encoder.2                │ SkipConnection             │ 33.0 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 24 </span>│ critic.encoder.3                │ Normalization              │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 25 </span>│ critic.value_head               │ CriticDecoder              │ 41.5 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 26 </span>│ critic.value_head.project_graph │ Linear                     │  8.3 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 27 </span>│ critic.value_head.project_node  │ Linear                     │  8.3 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 28 </span>│ critic.value_head.MLP           │ MLP                        │ 25.0 K │ train │\n",
       "└────┴─────────────────────────────────┴────────────────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m  \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName                           \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0 \u001b[0m\u001b[2m \u001b[0m│ env                             │ ATSPkoptEnv                │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1 \u001b[0m\u001b[2m \u001b[0m│ policy                          │ NeuOptPolicy               │  1.3 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2 \u001b[0m\u001b[2m \u001b[0m│ policy.encoder                  │ N2SEncoder                 │  940 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3 \u001b[0m\u001b[2m \u001b[0m│ policy.encoder.init_embedding   │ CustomizeATSPInitEmbedding │  612 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m4 \u001b[0m\u001b[2m \u001b[0m│ policy.encoder.pos_embedding    │ CyclicPositionalEmbedding  │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m5 \u001b[0m\u001b[2m \u001b[0m│ policy.encoder.pos_net          │ MultiHeadCompat            │ 32.8 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m6 \u001b[0m\u001b[2m \u001b[0m│ policy.encoder.net              │ AdaptiveSequential         │  295 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m7 \u001b[0m\u001b[2m \u001b[0m│ policy.decoder                  │ RDSDecoder                 │  329 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m8 \u001b[0m\u001b[2m \u001b[0m│ policy.decoder.linear_K1        │ Linear                     │ 16.4 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m9 \u001b[0m\u001b[2m \u001b[0m│ policy.decoder.linear_K2        │ Linear                     │ 16.4 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m10\u001b[0m\u001b[2m \u001b[0m│ policy.decoder.linear_K3        │ Linear                     │ 16.4 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m11\u001b[0m\u001b[2m \u001b[0m│ policy.decoder.linear_K4        │ Linear                     │ 16.4 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m12\u001b[0m\u001b[2m \u001b[0m│ policy.decoder.linear_Q1        │ Linear                     │ 16.4 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m13\u001b[0m\u001b[2m \u001b[0m│ policy.decoder.linear_Q2        │ Linear                     │ 16.4 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m14\u001b[0m\u001b[2m \u001b[0m│ policy.decoder.linear_Q3        │ Linear                     │ 16.4 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m15\u001b[0m\u001b[2m \u001b[0m│ policy.decoder.linear_Q4        │ Linear                     │ 16.4 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m16\u001b[0m\u001b[2m \u001b[0m│ policy.decoder.rnn1             │ GRUCell                    │ 99.1 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m17\u001b[0m\u001b[2m \u001b[0m│ policy.decoder.rnn2             │ GRUCell                    │ 99.1 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m18\u001b[0m\u001b[2m \u001b[0m│ policy.init_hidden_W            │ Linear                     │ 16.5 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m19\u001b[0m\u001b[2m \u001b[0m│ critic                          │ CriticNetwork              │  140 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m20\u001b[0m\u001b[2m \u001b[0m│ critic.encoder                  │ MultiHeadAttentionLayer    │ 98.6 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m21\u001b[0m\u001b[2m \u001b[0m│ critic.encoder.0                │ SkipConnection             │ 65.5 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m22\u001b[0m\u001b[2m \u001b[0m│ critic.encoder.1                │ Normalization              │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m23\u001b[0m\u001b[2m \u001b[0m│ critic.encoder.2                │ SkipConnection             │ 33.0 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m24\u001b[0m\u001b[2m \u001b[0m│ critic.encoder.3                │ Normalization              │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m25\u001b[0m\u001b[2m \u001b[0m│ critic.value_head               │ CriticDecoder              │ 41.5 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m26\u001b[0m\u001b[2m \u001b[0m│ critic.value_head.project_graph │ Linear                     │  8.3 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m27\u001b[0m\u001b[2m \u001b[0m│ critic.value_head.project_node  │ Linear                     │  8.3 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m28\u001b[0m\u001b[2m \u001b[0m│ critic.value_head.MLP           │ MLP                        │ 25.0 K │ train │\n",
       "└────┴─────────────────────────────────┴────────────────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 1.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 1.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 5                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 104                                                                                         \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 1.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 1.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 5                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 104                                                                                         \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9dbde20b27346c9b54f703d9e5700b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shora/Research/rl4co/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/home/shora/Research/rl4co/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/home/shora/Research/rl4co/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (8) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3652461ac0e34e6d971e284711311cdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b26fa4b5e5242638890d8ebb3148990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "336cdb6d32da45d384408deebd3fe2b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit and test the model\n",
    "trainer.fit(model)\n",
    "trainer.test(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rl-venv)",
   "language": "python",
   "name": "rl-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
