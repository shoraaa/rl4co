{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1b8b052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, RichModelSummary\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34a78b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl4co.envs import SSPEnv\n",
    "from rl4co.models.zoo.am import AttentionModelPolicy, AttentionModel\n",
    "from rl4co.utils.trainer import RL4COTrainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bce32d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSP codes:\n",
      " tensor([[0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0.],\n",
      "        [0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0.],\n",
      "        [0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0.],\n",
      "        [0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0.],\n",
      "        [1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0.]]) \n",
      "\n",
      " Suggested order: tensor([5, 1, 4, 0, 2, 9, 8, 6, 7, 3]) \n",
      "\n",
      " Sorted codes according to the order:\n",
      " tensor([[0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0.],\n",
      "        [1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0.],\n",
      "        [0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1.],\n",
      "        [0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0.],\n",
      "        [0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0.],\n",
      "        [1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.]])\n",
      "\n",
      "Constructed Superstring: 01100110111010000000011101011110001111001001110011100011000011011101000101011111000010011101111000011000001011010101110110100110011101101111\n",
      "Superstring Length: 140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shora/Research/rl4co/.venv/lib/python3.13/site-packages/torchrl/data/tensor_specs.py:6705: DeprecationWarning: The BoundedTensorSpec has been deprecated and will be removed in v0.8. Please use Bounded instead.\n",
      "  warnings.warn(\n",
      "/home/shora/Research/rl4co/.venv/lib/python3.13/site-packages/torchrl/data/tensor_specs.py:6705: DeprecationWarning: The UnboundedDiscreteTensorSpec has been deprecated and will be removed in v0.8. Please use Unbounded instead.\n",
      "  warnings.warn(\n",
      "/home/shora/Research/rl4co/.venv/lib/python3.13/site-packages/torchrl/data/tensor_specs.py:6705: DeprecationWarning: The CompositeSpec has been deprecated and will be removed in v0.8. Please use Composite instead.\n",
      "  warnings.warn(\n",
      "/home/shora/Research/rl4co/.venv/lib/python3.13/site-packages/torchrl/data/tensor_specs.py:6705: DeprecationWarning: The UnboundedContinuousTensorSpec has been deprecated and will be removed in v0.8. Please use Unbounded instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([-14.0000, -13.9000, -13.8000]), None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rl4co.utils.decoding import random_policy, rollout\n",
    "from rl4co.utils.ops import gather_by_index\n",
    "\n",
    "# RL4CO env based on TorchRL\n",
    "env = SSPEnv(generator_params=dict(num_loc=10, fixed_len=15))\n",
    "td = env.reset(batch_size=[3])\n",
    "# env.render(td)\n",
    "\n",
    "reward, td, actions = rollout(env, env.reset(batch_size=[3]), random_policy)\n",
    "reward, env.render(td, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56255fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shora/Research/rl4co/.venv/lib/python3.13/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'env' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['env'])`.\n",
      "/home/shora/Research/rl4co/.venv/lib/python3.13/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'policy' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['policy'])`.\n"
     ]
    }
   ],
   "source": [
    "class SSPInitEmbedding(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, fixed_len, linear_bias=True):\n",
    "        super(SSPInitEmbedding, self).__init__()\n",
    "        node_dim = fixed_len  # x, y\n",
    "        self.init_embed = nn.Linear(node_dim, embedding_dim, linear_bias)\n",
    "\n",
    "    def forward(self, td):\n",
    "        out = self.init_embed(td[\"codes\"])\n",
    "        return out\n",
    "\n",
    "class SSPContext(nn.Module):\n",
    "    \"\"\"Context embedding for the Traveling Salesman Problem (TSP).\n",
    "    Project the following to the embedding space:\n",
    "        - first node embedding\n",
    "        - current node embedding\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embedding_dim,  linear_bias=True):\n",
    "        super(SSPContext, self).__init__()\n",
    "        self.W_placeholder = nn.Parameter(\n",
    "            torch.Tensor(embedding_dim).uniform_(-1, 1)\n",
    "        )\n",
    "        self.project_context = nn.Linear(\n",
    "            embedding_dim, embedding_dim, bias=linear_bias\n",
    "        )\n",
    "\n",
    "    def forward(self, embeddings, td):\n",
    "        batch_size = embeddings.size(0)\n",
    "        # By default, node_dim = -1 (we only have one node embedding per node)\n",
    "        node_dim = (\n",
    "            (-1,) if td[\"current_node\"].dim() == 1 else (td[\"current_node\"].size(-1), -1)\n",
    "        )\n",
    "        if td[\"i\"][(0,) * td[\"i\"].dim()].item() < 1:  # get first item fast\n",
    "            context_embedding = self.W_placeholder[None, :].expand(\n",
    "                batch_size, self.W_placeholder.size(-1)\n",
    "            )\n",
    "        else:\n",
    "            context_embedding = gather_by_index(\n",
    "                embeddings,\n",
    "                torch.stack([td[\"current_node\"]], -1).view(\n",
    "                    batch_size, -1\n",
    "                ),\n",
    "            ).view(batch_size, *node_dim)\n",
    "        return self.project_context(context_embedding)\n",
    "        \n",
    "class StaticEmbedding(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(StaticEmbedding, self).__init__()\n",
    "\n",
    "    def forward(self, td):\n",
    "        return 0, 0, 0\n",
    "\n",
    "num_loc = 100\n",
    "fixed_len = 15\n",
    "emb_dim = 128\n",
    "\n",
    "env = SSPEnv(generator_params={\"num_loc\":num_loc,\n",
    "                              \"fixed_len\":fixed_len})\n",
    "\n",
    "policy = AttentionModelPolicy(env_name = env.name,\n",
    "                              embed_dim=emb_dim,\n",
    "                              num_encoder_layers=6,\n",
    "                              num_heads=8,\n",
    "                              normalization=\"instance\",\n",
    "                              init_embedding=SSPInitEmbedding(emb_dim, fixed_len),\n",
    "                              context_embedding=SSPContext(emb_dim),\n",
    "                              dynamic_embedding=StaticEmbedding(emb_dim),\n",
    "                              use_graph_context=False\n",
    "                             )\n",
    "\n",
    "# Model: default is AM with REINFORCE and greedy rollout baseline\n",
    "model = AttentionModel(env, \n",
    "            policy=policy,\n",
    "            batch_size=512,\n",
    "            train_data_size=100000,  # each epoch,\n",
    "            val_batch_size=1000,\n",
    "            val_data_size=1000,\n",
    "            test_batch_size=1000,\n",
    "            test_data_size=1000,\n",
    "            optimizer=\"Adam\",\n",
    "            optimizer_kwargs={\"lr\": 1e-4, \"weight_decay\": 1e-6},\n",
    "            lr_scheduler=\"MultiStepLR\",\n",
    "            lr_scheduler_kwargs={\"milestones\": [901, ], \"gamma\": 0.1},\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11ec7910",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/shora/Research/rl4co/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/shora/Research/rl4co/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66118239d5ea462faa72c3a57a10d605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test/reward        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    -13.337180137634277    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test/reward       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   -13.337180137634277   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shora/Research/rl4co/.venv/lib/python3.13/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /home/shora/Research/rl4co/checkpoints_ssp exists and is not empty.\n",
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">    </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name                                   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                  </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0  </span>│ env                                    │ SSPEnv                │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1  </span>│ policy                                 │ AttentionModelPolicy  │  1.3 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2  </span>│ policy.encoder                         │ AttentionModelEncoder │  1.2 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3  </span>│ policy.encoder.init_embedding          │ SSPInitEmbedding      │  2.0 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4  </span>│ policy.encoder.net                     │ GraphAttentionNetwork │  1.2 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5  </span>│ policy.decoder                         │ AttentionModelDecoder │ 98.6 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6  </span>│ policy.decoder.context_embedding       │ SSPContext            │ 16.6 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7  </span>│ policy.decoder.dynamic_embedding       │ StaticEmbedding       │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8  </span>│ policy.decoder.pointer                 │ PointerAttention      │ 16.4 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9  </span>│ policy.decoder.project_node_embeddings │ Linear                │ 49.2 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 10 </span>│ policy.decoder.project_fixed_context   │ Linear                │ 16.4 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 11 </span>│ baseline                               │ WarmupBaseline        │  1.3 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 12 </span>│ baseline.baseline                      │ RolloutBaseline       │  1.3 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 13 </span>│ baseline.baseline.policy               │ AttentionModelPolicy  │  1.3 M │ eval  │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 14 </span>│ baseline.warmup_baseline               │ ExponentialBaseline   │      0 │ train │\n",
       "└────┴────────────────────────────────────────┴───────────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m  \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName                                  \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                 \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0 \u001b[0m\u001b[2m \u001b[0m│ env                                    │ SSPEnv                │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1 \u001b[0m\u001b[2m \u001b[0m│ policy                                 │ AttentionModelPolicy  │  1.3 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2 \u001b[0m\u001b[2m \u001b[0m│ policy.encoder                         │ AttentionModelEncoder │  1.2 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3 \u001b[0m\u001b[2m \u001b[0m│ policy.encoder.init_embedding          │ SSPInitEmbedding      │  2.0 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m4 \u001b[0m\u001b[2m \u001b[0m│ policy.encoder.net                     │ GraphAttentionNetwork │  1.2 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m5 \u001b[0m\u001b[2m \u001b[0m│ policy.decoder                         │ AttentionModelDecoder │ 98.6 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m6 \u001b[0m\u001b[2m \u001b[0m│ policy.decoder.context_embedding       │ SSPContext            │ 16.6 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m7 \u001b[0m\u001b[2m \u001b[0m│ policy.decoder.dynamic_embedding       │ StaticEmbedding       │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m8 \u001b[0m\u001b[2m \u001b[0m│ policy.decoder.pointer                 │ PointerAttention      │ 16.4 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m9 \u001b[0m\u001b[2m \u001b[0m│ policy.decoder.project_node_embeddings │ Linear                │ 49.2 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m10\u001b[0m\u001b[2m \u001b[0m│ policy.decoder.project_fixed_context   │ Linear                │ 16.4 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m11\u001b[0m\u001b[2m \u001b[0m│ baseline                               │ WarmupBaseline        │  1.3 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m12\u001b[0m\u001b[2m \u001b[0m│ baseline.baseline                      │ RolloutBaseline       │  1.3 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m13\u001b[0m\u001b[2m \u001b[0m│ baseline.baseline.policy               │ AttentionModelPolicy  │  1.3 M │ eval  │\n",
       "│\u001b[2m \u001b[0m\u001b[2m14\u001b[0m\u001b[2m \u001b[0m│ baseline.warmup_baseline               │ ExponentialBaseline   │      0 │ train │\n",
       "└────┴────────────────────────────────────────┴───────────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.6 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.6 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 10                                                                         \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 126                                                                                         \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 122                                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.6 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.6 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 10                                                                         \n",
       "\u001b[1mModules in train mode\u001b[0m: 126                                                                                         \n",
       "\u001b[1mModules in eval mode\u001b[0m: 122                                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1203615342864db28e3abe191c78d5d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shora/Research/rl4co/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/home/shora/Research/rl4co/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7376778cd6f473285e8500b4d6e80d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2f7d1e3503c41399971de0d0b2e7bd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac6766dc70c34179bce08b9a3384eb69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e403a9a5f83493790d7da1c401bf995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    }
   ],
   "source": [
    "# Checkpointing callback: save models when validation reward improves\n",
    "checkpoint_callback = ModelCheckpoint(dirpath=\"checkpoints_ssp\", # save to checkpoints/\n",
    "                                    filename=\"epoch_{epoch:03d}\",  # save as epoch_XXX.ckpt\n",
    "                                    save_top_k=5, # save only the best model\n",
    "                                    save_last=True, # save the last model\n",
    "                                    monitor=\"val/reward\", # monitor validation reward\n",
    "                                    mode=\"max\") # maximize validation reward\n",
    "\n",
    "rich_model_summary = RichModelSummary(max_depth=3)  # model summary callback\n",
    "callbacks = [checkpoint_callback, rich_model_summary]\n",
    "\n",
    "# Logger\n",
    "# logger = WandbLogger(project=\"rl4co\", name=f\"{env.name}_{num_loc}\")\n",
    "logger = None # uncomment this line if you don't want logging\n",
    "\n",
    "\n",
    "\n",
    "# We use our own wrapper around Lightning's `Trainer` to make it easier to use\n",
    "trainer = RL4COTrainer(max_epochs=3, \n",
    "                       accelerator = 'gpu', \n",
    "                       devices=1,   \n",
    "                       # logger=logger,\n",
    "                       callbacks=callbacks,\n",
    "                      )\n",
    "\n",
    "trainer.test(model)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "400b6ca2",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m td = env.reset(batch_size=[\u001b[32m3\u001b[39m]).to(device)  \u001b[38;5;66;03m# Move td to the same device as the environment\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# env.render(td)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m reward, td, actions = \u001b[43mrollout\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Ensure td is on the correct device\u001b[39;00m\n\u001b[32m      6\u001b[39m reward, env.render(td, actions)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/rl4co/rl4co/utils/decoding.py:97\u001b[39m, in \u001b[36mrollout\u001b[39m\u001b[34m(env, td, policy, max_steps)\u001b[39m\n\u001b[32m     94\u001b[39m steps = \u001b[32m0\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m td[\u001b[33m\"\u001b[39m\u001b[33mdone\u001b[39m\u001b[33m\"\u001b[39m].all():\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m     td = \u001b[43mpolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     98\u001b[39m     actions.append(td[\u001b[33m\"\u001b[39m\u001b[33maction\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     99\u001b[39m     td = env.step(td)[\u001b[33m\"\u001b[39m\u001b[33mnext\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/rl4co/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/rl4co/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/rl4co/rl4co/models/common/constructive/base.py:195\u001b[39m, in \u001b[36mConstructivePolicy.forward\u001b[39m\u001b[34m(self, td, env, phase, calc_reward, return_actions, return_entropy, return_hidden, return_init_embeds, return_sum_log_likelihood, actions, max_steps, **decoding_kwargs)\u001b[39m\n\u001b[32m    172\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Forward pass of the policy.\u001b[39;00m\n\u001b[32m    173\u001b[39m \n\u001b[32m    174\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    191\u001b[39m \u001b[33;03m    out: Dictionary containing the reward, log likelihood, and optionally the actions and entropy\u001b[39;00m\n\u001b[32m    192\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    194\u001b[39m \u001b[38;5;66;03m# Encoder: get encoder output and initial embeddings from initial state\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m hidden, init_embeds = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[38;5;66;03m# Instantiate environment if needed\u001b[39;00m\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(env, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m env \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/rl4co/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/rl4co/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/rl4co/rl4co/models/zoo/am/encoder.py:85\u001b[39m, in \u001b[36mAttentionModelEncoder.forward\u001b[39m\u001b[34m(self, td, mask)\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Forward pass of the encoder.\u001b[39;00m\n\u001b[32m     74\u001b[39m \u001b[33;03mTransform the input TensorDict into a latent representation.\u001b[39;00m\n\u001b[32m     75\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     82\u001b[39m \u001b[33;03m    init_h: Initial embedding of the input\u001b[39;00m\n\u001b[32m     83\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     84\u001b[39m \u001b[38;5;66;03m# Transfer to embedding space\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m init_h = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minit_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;66;03m# Process embedding\u001b[39;00m\n\u001b[32m     88\u001b[39m h = \u001b[38;5;28mself\u001b[39m.net(init_h, mask)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/rl4co/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/rl4co/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mSSPInitEmbedding.forward\u001b[39m\u001b[34m(self, td)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, td):\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minit_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtd\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcodes\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/rl4co/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/rl4co/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/rl4co/.venv/lib/python3.13/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "td = env.reset(batch_size=[3]).to(device)  # Move td to the same device as the environment\n",
    "# env.render(td)\n",
    "\n",
    "reward, td, actions = rollout(env, env.reset(batch_size=[3]).to(device), policy)  # Ensure td is on the correct device\n",
    "reward, env.render(td, actions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rl-venv)",
   "language": "python",
   "name": "rl-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
